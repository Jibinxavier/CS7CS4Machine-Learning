{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AABABUTdx7YqCeBquA1Ky7z8a/The%20SUM%20dataset?dl=1#\"\n",
    "housing_price_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AAAVLZzU4E7ro0BiRzPG3pP8a/House%20Prices?dl=1\"\n",
    "titanic_data_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AADfweTUjMlkayMQ6JvKUOGia/Wine%20Quality%20Ratings%20and%20Chemicals?dl=0\"\n",
    "all_urls = [sumdata_url, housing_price_url, titanic_data_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_data(all_urls) # retrieves the data if there is no data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_noise_path = \"data/with noise/The SUM dataset, with noise.csv\"\n",
    "sumdata_path = \"data/without noise/The SUM dataset, without noise.csv\"\n",
    "housing_price_path = \"data/housing dataset.csv\" # has more than 30 features\n",
    "titanic_path = \"data/titanic dataset.csv\"\n",
    "# census_path = \"data/adult.csv\"\n",
    "# need one more\n",
    "# what a brilliant idea to name files with space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sum_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5 (meaningless but please still use it)</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>Noisy Target</th>\n",
       "      <th>Noisy Target Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62485</td>\n",
       "      <td>58472</td>\n",
       "      <td>84200</td>\n",
       "      <td>86181</td>\n",
       "      <td>75529</td>\n",
       "      <td>136939</td>\n",
       "      <td>150633</td>\n",
       "      <td>230058</td>\n",
       "      <td>246491</td>\n",
       "      <td>257336</td>\n",
       "      <td>1352179</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75559</td>\n",
       "      <td>119137</td>\n",
       "      <td>146760</td>\n",
       "      <td>139674</td>\n",
       "      <td>19582</td>\n",
       "      <td>177083</td>\n",
       "      <td>217746</td>\n",
       "      <td>321110</td>\n",
       "      <td>434444</td>\n",
       "      <td>516798</td>\n",
       "      <td>1976446</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26568</td>\n",
       "      <td>30742</td>\n",
       "      <td>28693</td>\n",
       "      <td>36891</td>\n",
       "      <td>24065</td>\n",
       "      <td>60797</td>\n",
       "      <td>79331</td>\n",
       "      <td>84997</td>\n",
       "      <td>116275</td>\n",
       "      <td>129739</td>\n",
       "      <td>558391</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28982</td>\n",
       "      <td>26455</td>\n",
       "      <td>30320</td>\n",
       "      <td>36811</td>\n",
       "      <td>6298</td>\n",
       "      <td>51776</td>\n",
       "      <td>60652</td>\n",
       "      <td>92309</td>\n",
       "      <td>104381</td>\n",
       "      <td>102250</td>\n",
       "      <td>517918</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48819</td>\n",
       "      <td>64900</td>\n",
       "      <td>76502</td>\n",
       "      <td>66164</td>\n",
       "      <td>52350</td>\n",
       "      <td>142914</td>\n",
       "      <td>161493</td>\n",
       "      <td>174927</td>\n",
       "      <td>187274</td>\n",
       "      <td>283998</td>\n",
       "      <td>1255271</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28229</td>\n",
       "      <td>41920</td>\n",
       "      <td>53861</td>\n",
       "      <td>59145</td>\n",
       "      <td>61156</td>\n",
       "      <td>74633</td>\n",
       "      <td>100096</td>\n",
       "      <td>140345</td>\n",
       "      <td>160827</td>\n",
       "      <td>158400</td>\n",
       "      <td>792932</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13367</td>\n",
       "      <td>15027</td>\n",
       "      <td>18032</td>\n",
       "      <td>25529</td>\n",
       "      <td>1464</td>\n",
       "      <td>35011</td>\n",
       "      <td>47895</td>\n",
       "      <td>59491</td>\n",
       "      <td>50819</td>\n",
       "      <td>70421</td>\n",
       "      <td>322168</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32997</td>\n",
       "      <td>37556</td>\n",
       "      <td>39679</td>\n",
       "      <td>69952</td>\n",
       "      <td>34100</td>\n",
       "      <td>94806</td>\n",
       "      <td>95483</td>\n",
       "      <td>136521</td>\n",
       "      <td>144810</td>\n",
       "      <td>166752</td>\n",
       "      <td>875855</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37107</td>\n",
       "      <td>37107</td>\n",
       "      <td>47671</td>\n",
       "      <td>55948</td>\n",
       "      <td>33723</td>\n",
       "      <td>76945</td>\n",
       "      <td>92334</td>\n",
       "      <td>114712</td>\n",
       "      <td>140783</td>\n",
       "      <td>191464</td>\n",
       "      <td>746427</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20694</td>\n",
       "      <td>27936</td>\n",
       "      <td>42090</td>\n",
       "      <td>50509</td>\n",
       "      <td>105598</td>\n",
       "      <td>54067</td>\n",
       "      <td>86508</td>\n",
       "      <td>77857</td>\n",
       "      <td>93428</td>\n",
       "      <td>114783</td>\n",
       "      <td>550836</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0      62485      58472      84200      86181   \n",
       "1      75559     119137     146760     139674   \n",
       "2      26568      30742      28693      36891   \n",
       "3      28982      26455      30320      36811   \n",
       "4      48819      64900      76502      66164   \n",
       "5      28229      41920      53861      59145   \n",
       "6      13367      15027      18032      25529   \n",
       "7      32997      37556      39679      69952   \n",
       "8      37107      37107      47671      55948   \n",
       "9      20694      27936      42090      50509   \n",
       "\n",
       "   Feature 5 (meaningless but please still use it)  Feature 6  Feature 7  \\\n",
       "0                                            75529     136939     150633   \n",
       "1                                            19582     177083     217746   \n",
       "2                                            24065      60797      79331   \n",
       "3                                             6298      51776      60652   \n",
       "4                                            52350     142914     161493   \n",
       "5                                            61156      74633     100096   \n",
       "6                                             1464      35011      47895   \n",
       "7                                            34100      94806      95483   \n",
       "8                                            33723      76945      92334   \n",
       "9                                           105598      54067      86508   \n",
       "\n",
       "   Feature 8  Feature 9  Feature 10  Noisy Target Noisy Target Class  \n",
       "0     230058     246491      257336       1352179  Very Large Number  \n",
       "1     321110     434444      516798       1976446  Very Large Number  \n",
       "2      84997     116275      129739        558391  Very Large Number  \n",
       "3      92309     104381      102250        517918  Very Large Number  \n",
       "4     174927     187274      283998       1255271  Very Large Number  \n",
       "5     140345     160827      158400        792932  Very Large Number  \n",
       "6      59491      50819       70421        322168       Large Number  \n",
       "7     136521     144810      166752        875855  Very Large Number  \n",
       "8     114712     140783      191464        746427  Very Large Number  \n",
       "9      77857      93428      114783        550836  Very Large Number  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata_noise = pd.read_csv(sumdata_noise_path, delimiter=\";\")\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "sumdata_noise = sumdata_noise.drop('Instance', axis = 1)\n",
    "sumdata_noise.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sum_noise dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 'Nosiy Target' as regression target\n",
    "sumdata_noise_reg_Y = sumdata_noise['Noisy Target'].values.reshape(-1, 1)\n",
    "\n",
    "# Use 'Nosiy Target Class' Large Number as regression target\n",
    "sumdata_noise_classif_Y = pd.get_dummies(sumdata_noise['Noisy Target Class']).iloc[:, 0]\n",
    "sumdata_noise_classif_Y = sumdata_noise_classif_Y.values.astype(int).reshape(-1,1)\n",
    "\n",
    "# Use rest columns as explananatory variables\n",
    "# We can simply use the same features for both as Noisy Target and Noisy Target Class are representing the samething\n",
    "sumdata_noise_reg_X = sumdata_noise.iloc[:, 0:-2].values\n",
    "sumdata_noise_classif_X = sumdata_noise.iloc[:, 0:-2].values\n",
    "\n",
    "# Apply Feature Scaling for the classification variable\n",
    "# As we are using KNN \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "sumdata_noise_classif_X = scX.fit_transform(sumdata_noise_classif_X)\n",
    "sumdata_noise_classif_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sumdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5 (meaningless but please still use it)</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57326</td>\n",
       "      <td>68791</td>\n",
       "      <td>82549</td>\n",
       "      <td>99059</td>\n",
       "      <td>72624</td>\n",
       "      <td>142645</td>\n",
       "      <td>171174</td>\n",
       "      <td>205409</td>\n",
       "      <td>246491</td>\n",
       "      <td>295789</td>\n",
       "      <td>1369233</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87859</td>\n",
       "      <td>105431</td>\n",
       "      <td>126517</td>\n",
       "      <td>151820</td>\n",
       "      <td>19982</td>\n",
       "      <td>218621</td>\n",
       "      <td>262345</td>\n",
       "      <td>314814</td>\n",
       "      <td>377777</td>\n",
       "      <td>453332</td>\n",
       "      <td>2098516</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23721</td>\n",
       "      <td>28465</td>\n",
       "      <td>34158</td>\n",
       "      <td>40990</td>\n",
       "      <td>20054</td>\n",
       "      <td>59026</td>\n",
       "      <td>70831</td>\n",
       "      <td>84997</td>\n",
       "      <td>101996</td>\n",
       "      <td>122395</td>\n",
       "      <td>566579</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24771</td>\n",
       "      <td>29725</td>\n",
       "      <td>35670</td>\n",
       "      <td>42804</td>\n",
       "      <td>7775</td>\n",
       "      <td>61638</td>\n",
       "      <td>73966</td>\n",
       "      <td>88759</td>\n",
       "      <td>106511</td>\n",
       "      <td>127813</td>\n",
       "      <td>591657</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47862</td>\n",
       "      <td>57434</td>\n",
       "      <td>68921</td>\n",
       "      <td>82705</td>\n",
       "      <td>60872</td>\n",
       "      <td>119095</td>\n",
       "      <td>142914</td>\n",
       "      <td>171497</td>\n",
       "      <td>205796</td>\n",
       "      <td>246955</td>\n",
       "      <td>1143179</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35286</td>\n",
       "      <td>42343</td>\n",
       "      <td>50812</td>\n",
       "      <td>60974</td>\n",
       "      <td>51392</td>\n",
       "      <td>87803</td>\n",
       "      <td>105364</td>\n",
       "      <td>126437</td>\n",
       "      <td>151724</td>\n",
       "      <td>182069</td>\n",
       "      <td>842812</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14070</td>\n",
       "      <td>16884</td>\n",
       "      <td>20261</td>\n",
       "      <td>24313</td>\n",
       "      <td>1509</td>\n",
       "      <td>35011</td>\n",
       "      <td>42013</td>\n",
       "      <td>50416</td>\n",
       "      <td>60499</td>\n",
       "      <td>72599</td>\n",
       "      <td>336066</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34018</td>\n",
       "      <td>40822</td>\n",
       "      <td>48986</td>\n",
       "      <td>58783</td>\n",
       "      <td>38750</td>\n",
       "      <td>84648</td>\n",
       "      <td>101578</td>\n",
       "      <td>121894</td>\n",
       "      <td>146273</td>\n",
       "      <td>175528</td>\n",
       "      <td>812530</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36379</td>\n",
       "      <td>43655</td>\n",
       "      <td>52386</td>\n",
       "      <td>62863</td>\n",
       "      <td>29843</td>\n",
       "      <td>90523</td>\n",
       "      <td>108628</td>\n",
       "      <td>130354</td>\n",
       "      <td>156425</td>\n",
       "      <td>187710</td>\n",
       "      <td>868923</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25867</td>\n",
       "      <td>31040</td>\n",
       "      <td>37248</td>\n",
       "      <td>44698</td>\n",
       "      <td>92630</td>\n",
       "      <td>64366</td>\n",
       "      <td>77239</td>\n",
       "      <td>92687</td>\n",
       "      <td>111224</td>\n",
       "      <td>133469</td>\n",
       "      <td>617838</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0      57326      68791      82549      99059   \n",
       "1      87859     105431     126517     151820   \n",
       "2      23721      28465      34158      40990   \n",
       "3      24771      29725      35670      42804   \n",
       "4      47862      57434      68921      82705   \n",
       "5      35286      42343      50812      60974   \n",
       "6      14070      16884      20261      24313   \n",
       "7      34018      40822      48986      58783   \n",
       "8      36379      43655      52386      62863   \n",
       "9      25867      31040      37248      44698   \n",
       "\n",
       "   Feature 5 (meaningless but please still use it)  Feature 6  Feature 7  \\\n",
       "0                                            72624     142645     171174   \n",
       "1                                            19982     218621     262345   \n",
       "2                                            20054      59026      70831   \n",
       "3                                             7775      61638      73966   \n",
       "4                                            60872     119095     142914   \n",
       "5                                            51392      87803     105364   \n",
       "6                                             1509      35011      42013   \n",
       "7                                            38750      84648     101578   \n",
       "8                                            29843      90523     108628   \n",
       "9                                            92630      64366      77239   \n",
       "\n",
       "   Feature 8  Feature 9  Feature 10   Target       Target Class  \n",
       "0     205409     246491      295789  1369233  Very Large Number  \n",
       "1     314814     377777      453332  2098516  Very Large Number  \n",
       "2      84997     101996      122395   566579  Very Large Number  \n",
       "3      88759     106511      127813   591657  Very Large Number  \n",
       "4     171497     205796      246955  1143179  Very Large Number  \n",
       "5     126437     151724      182069   842812  Very Large Number  \n",
       "6      50416      60499       72599   336066       Large Number  \n",
       "7     121894     146273      175528   812530  Very Large Number  \n",
       "8     130354     156425      187710   868923  Very Large Number  \n",
       "9      92687     111224      133469   617838  Very Large Number  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata = pd.read_csv(sumdata_path, delimiter=\";\")\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "sumdata = sumdata.drop('Instance', axis = 1)\n",
    "sumdata.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sumdata dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest of the columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 'Nosiy Target' as regression target\n",
    "sumdata_reg_Y = sumdata['Target'].values.reshape(-1, 1)\n",
    "\n",
    "# Use 'Nosiy Target Class' Large Number as classification target\n",
    "sumdata_classif_Y = pd.get_dummies(sumdata['Target Class']).iloc[:, 0]\n",
    "sumdata_classif_Y = sumdata_classif_Y.values.astype(int).reshape(-1,1)\n",
    "\n",
    "# Use rest columns as explananatory variables\n",
    "# We can simply use the same features for both as Target and Target Class are representing the same thing\n",
    "sumdata_classif_X = sumdata.iloc[:, 0:-2].values\n",
    "sumdata_reg_X = sumdata.iloc[:, 0:-2].values\n",
    "\n",
    "# Apply Feature Scaling for the classification variable\n",
    "# As we are using KNN \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "sumdata_classif_X = scX.fit_transform(sumdata_classif_X)\n",
    "sumdata_classif_Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load House Price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/housing dataset.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-045e1cdfa40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhousing_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_price_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Remove 'Instance' as it simply represents the row number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhousing_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhousing_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/housing dataset.csv' does not exist"
     ]
    }
   ],
   "source": [
    "housing_price = pd.read_csv(housing_price_path)\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "housing_price = housing_price.drop('Id', axis = 1)\n",
    "housing_price.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess housing price dataset\n",
    "\n",
    "- Remove 'Id' as it simply represents the row number\n",
    "- Use 'SalePrice' as regression target\n",
    "- Use 'SaleCondition' as classification target\n",
    "- For explananatory variables, use the following numerical variable and categorical variables\n",
    "    - Numerical\n",
    "        - LotFrontage\n",
    "        - OverallQual\n",
    "        - OverallCond\n",
    "        - YearBuilt\n",
    "        - YearRemodAdd\n",
    "        - TotalBsmtSF\n",
    "        - GrLivArea\n",
    "        - FullBath\n",
    "        - TotRmsAbvGrd\n",
    "        - GarageYrBlt\n",
    "        - GarageCars\n",
    "        - GarageArea\n",
    "        - LotArea\n",
    "        - 1stFlrSF\n",
    "        - 2ndFlrSF\n",
    "    - Categorical\n",
    "        - YearSold\n",
    "        - Neighborhood\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'housing_price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1fb14947acbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                       'FullBath', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'LotArea', '1stFlrSF', '2ndFlrSF']\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhousing_price\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexplanatory_numeric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfiltered_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing_price\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexplanatory_numeric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfiltered_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'housing_price' is not defined"
     ]
    }
   ],
   "source": [
    "## filter unused categorical columns and drop NaN, we only want to keep 'neighborhood' and 'housestyle' \n",
    "## in our explanantory vairbale\n",
    "\n",
    "# get all the numerical data that is needed\n",
    "explanatory_numeric = ['OverallQual', 'LotFrontage', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', 'GrLivArea',\n",
    "                      'FullBath', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'LotArea', '1stFlrSF', '2ndFlrSF']\n",
    "\n",
    "housing_price[explanatory_numeric[0]]\n",
    "filtered_table = housing_price[explanatory_numeric[0]]\n",
    "filtered_table\n",
    "\n",
    "for c in explanatory_numeric[1:]:\n",
    "    filtered_table = pd.concat([filtered_table, housing_price[c]], axis=1)\n",
    "filtered_table\n",
    "\n",
    "# get the two categorical variable that we wants to use, convert it to dummy variable and avoid dummy variable trap\n",
    "filtered_table = pd.concat([filtered_table, pd.get_dummies(housing_price['Neighborhood']).iloc[:, :-1]], axis=1)\n",
    "filtered_table = pd.concat([filtered_table, pd.get_dummies(housing_price['YrSold']).iloc[:, :-1]], axis=1)\n",
    "\n",
    "# drop NaN\n",
    "filtered_table = filtered_table.dropna()\n",
    "filtered_table \n",
    "\n",
    "# get explanatory variable\n",
    "housing_price_reg_X = filtered_table[:].values\n",
    "housing_price_classif_X = filtered_table[:].values\n",
    "\n",
    "# get the regression target and classification target\n",
    "# I am using sales price as both regression and classification target\n",
    "# sale_price_classi = SalePrice<Mean, SalePrice>=Mean\n",
    "housing_price_reg_Y = housing_price['SalePrice'].values\n",
    "housing_price_classif_Y = np.zeros(housing_price_reg_Y.shape)\n",
    "house_price_mean = housing_price_reg_Y.mean()\n",
    "\n",
    "for i, price in enumerate(housing_price_reg_Y):\n",
    "    if price >= house_price_mean:\n",
    "        housing_price_classi_Y[i] = 1\n",
    "    else:\n",
    "        housing_price_classi_Y[i] = 0\n",
    "\n",
    "# Apply Feature Scaling to the numeric variables and regression target \n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "housing_price_classif_X = scX.fit_transform(housing_price_classif_X)\n",
    "housing_price_classif_Y = scY.fit_transform(housing_price_classif_Y.reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harper, Mrs. Henry Sleeper (Myna Haxtun)</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ostby, Mr. Engelhart Cornelius</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113509</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>B30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass                                               Name  \\\n",
       "1          1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3          1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "6          0       1                            McCarthy, Mr. Timothy J   \n",
       "10         1       3                    Sandstrom, Miss. Marguerite Rut   \n",
       "11         1       1                           Bonnell, Miss. Elizabeth   \n",
       "21         1       2                              Beesley, Mr. Lawrence   \n",
       "23         1       1                       Sloper, Mr. William Thompson   \n",
       "27         0       1                     Fortune, Mr. Charles Alexander   \n",
       "52         1       1           Harper, Mrs. Henry Sleeper (Myna Haxtun)   \n",
       "54         0       1                     Ostby, Mr. Engelhart Cornelius   \n",
       "\n",
       "       Sex   Age  SibSp  Parch    Ticket      Fare        Cabin Embarked  \n",
       "1   female  38.0      1      0  PC 17599   71.2833          C85        C  \n",
       "3   female  35.0      1      0    113803   53.1000         C123        S  \n",
       "6     male  54.0      0      0     17463   51.8625          E46        S  \n",
       "10  female   4.0      1      1   PP 9549   16.7000           G6        S  \n",
       "11  female  58.0      0      0    113783   26.5500         C103        S  \n",
       "21    male  34.0      0      0    248698   13.0000          D56        S  \n",
       "23    male  28.0      0      0    113788   35.5000           A6        S  \n",
       "27    male  19.0      3      2     19950  263.0000  C23 C25 C27        S  \n",
       "52  female  49.0      1      0  PC 17572   76.7292          D33        C  \n",
       "54    male  65.0      0      1    113509   61.9792          B30        C  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset = pd.read_csv(titanic_path)\n",
    "\n",
    "# Remove 'PassengerId' as it simply represents the row number\n",
    "titanic_dataset = titanic_dataset.drop('PassengerId', axis = 1)\n",
    "titanic_dataset = titanic_dataset.dropna()\n",
    "titanic_dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocess titanic dataset\n",
    "\n",
    "- Use 'Fare' as regression target\n",
    "    - explanatory variable\n",
    "        - Age\n",
    "        \n",
    "- Use 'Survived' as classification target\n",
    "    - explanatory variable\n",
    "        - Sex, female get the chance to survive\n",
    "        - Fare, rich people might get the chance to survive\n",
    "        - Age, will be divided as >12 and (<12), child get the chance to survive\n",
    "        \n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect varaibles needed for regression\n",
    "titanic_regression_X = titanic_dataset['Age'].values.reshape(-1, 1)\n",
    "titanic_regression_Y = titanic_dataset['Fare'].values.reshape(-1,1)\n",
    "\n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "titanic_regression_X = scX.fit_transform(titanic_regression_X)\n",
    "titanic_regression_Y = scX.fit_transform(titanic_regression_Y)\n",
    "\n",
    "# Collect varaibles needed for classification\n",
    "titanic_classification_X = titanic_dataset['Fare']\n",
    "titanic_classification_X = pd.concat([titanic_classification_X, pd.get_dummies(titanic_dataset['Sex']).iloc[:, :-1]], axis=1)\n",
    "titanic_classification_X = pd.concat([titanic_classification_X, titanic_dataset['Age']], axis=1)\n",
    "titanic_classification_y = titanic_dataset['Survived'].values.reshape(-1,1)\n",
    "\n",
    "# Apply Feature Scaling to the explanatory variables for classification\n",
    "scX = StandardScaler()\n",
    "titanic_classification_X = scX.fit_transform(titanic_classification_X)\n",
    "titanic_classification_X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fits Algorithms to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_chunks = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000,\n",
    "1000000, 5000000, 10000000, 50000000, 100000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from math import sqrt\n",
    "def root_mean_square_error(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model( X, y, dataset_name, algorithm, isReg): \n",
    "    \n",
    "    print (\"Algorithm: {}\\nDataset: {}\\n\".format( algorithm.__name__, dataset_name))\n",
    "    for chunk in data_chunks:\n",
    "        \n",
    "        # if chunk is greater than the no. of examples quite from the chunking\n",
    "        if chunk > X.shape[0]: \n",
    "            chunk = X.shape[0]\n",
    "        \n",
    "        print (\"Chunk Size: {}\\n\".format(chunk))\n",
    "        \n",
    "        # generate the chunk file\n",
    "        current_X = X[0:chunk]\n",
    "        current_y = y[0:chunk]\n",
    "        \n",
    "        kFoldModelling(current_X, current_y, 10, algorithm, isReg)\n",
    "        \n",
    "        if chunk == X.shape[0]:\n",
    "            break\n",
    "              \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kFoldModelling (X, y, kfolds, algorithm, isReg):\n",
    "    \n",
    "    kf = KFold(n_splits=kfolds)\n",
    "    rmse = np.zeros((10,1))\n",
    "    mae = np.zeros((10,1))\n",
    "    accuracy = np.zeros((10,1))\n",
    "    precision = np.zeros((10,1))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # fit the model to the datset\n",
    "        lm = algorithm()\n",
    "        lm.fit(X_train, y_train)\n",
    "        \n",
    "        if isReg:     \n",
    "            rmse[i] = root_mean_square_error(y_test, lm.predict(X_test))  # RMSE https://www.kaggle.com/wiki/RootMeanSquaredError\n",
    "            mae[i] = mean_absolute_error(y_test, lm.predict(X_test))\n",
    "        else:\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            accuracy[i] = accuracy_score(y_test, lm.predict(X_test))\n",
    "            precision[i] = precision_score(y_test, lm.predict(X_test))\n",
    "        # print the result, we will need to have method that genereates the result csv file required.\n",
    "    \n",
    "    if isReg:     \n",
    "        print (\"Iteration: {}\\nRMSE: {}\\nMAE: {}\\n\".format( i, rmse.mean(), mae.mean()))\n",
    "    else:\n",
    "        print (\"Iteration: {}\\Accuracy: {}\\nPrecision: {}\\n\".format( i, accuracy.mean(), precision.mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fits Regression Algorithms to datasets\n",
    "\n",
    "    - Linear Regression\n",
    "    - Random Forest Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model(sumdata_noise_reg_X, sumdata_noise_reg_Y, \"The Sum Dataset(with noise)\", LinearRegression, True)\n",
    "# model(sumdata_reg_X, sumdata_reg_Y, \"The Sum Dataset(without noise)\",  LinearRegression, True)\n",
    "# model(housing_price_reg_X, housing_price_reg_Y, \"Housing Dataset\",  LinearRegression, True)\n",
    "# model(titanic_regression_X, titanic_regression_Y, \"Titanic Dataset\", LinearRegression, True)\n",
    "\n",
    "# model(sumdata_noise_reg_X, sumdata_noise_reg_Y,\"The Sum Dataset(with noise)\",  RandomForestRegressor, True)\n",
    "# model(sumdata_reg_X, sumdata_reg_Y, \"The Sum Dataset(without noise)\", RandomForestRegressor, True)\n",
    "# model(housing_price_reg_X, housing_price_reg_Y, \"Housing Dataset\", RandomForestRegressor, True)\n",
    "# model(titanic_regression_X, titanic_regression_Y, \"Titanic Dataset\", RandomForestRegressor, True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# model(sumdata_noise_classif_X, sumdata_noise_classif_Y, \"The Sum Dataset(with noise)\", LogisticRegression, False)\n",
    "# model(sumdata_classif_X, sumdata_classif_Y, \"The Sum Dataset(without noise)\", LogisticRegression, False)\n",
    "# model(housing_price_classif_X, housing_price_classif_Y, \"Housing Dataset\", LogisticRegression, False)\n",
    "housing_price_classif_Y\n",
    "# model(titanic_classification_X, titanic_classification_y, \"Titanic Dataset\", LogisticRegression, False)\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# model(sumdata_noise_classi_X, sumdata_noise_classif_Y, \"The Sum Dataset(with noise)\", SVC, False)\n",
    "# model(sumdata_classi_X, sumdata_classif_Y, \"The Sum Dataset(without noise)\", SVC, False)\n",
    "# model(housing_price_classi_X, housing_price_classif_Y, \"Housing Dataset\", SVC, False)\n",
    "# model(titanic_classification_X, titanic_classification_y, \"Titanic Dataset\", SVC, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

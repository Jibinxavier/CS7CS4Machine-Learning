{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdata_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AABABUTdx7YqCeBquA1Ky7z8a/The%20SUM%20dataset?dl=1#\"\n",
    "census_url  = \"https://www.dropbox.com/sh/euppz607r6gsen2/AADfweTUjMlkayMQ6JvKUOGia/Census-Income%20(KDD)%20Data%20Set?dl=1\"\n",
    "housing_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AAD6JGlvG5XADIjg9SCojvpya/House%20Sales%20in%20King%20County%2C%20USA?dl=1&preview=kc_house_data.csv\"\n",
    "all_urls = [census_url,sumdata_url,housing_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(all_urls) # retrieves the data if there is no data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_noise_path = \"data/with noise/The SUM dataset, with noise.csv\"\n",
    "sumdata_path = \"data/without noise/The SUM dataset, without noise.csv\" \n",
    "housing_sales_path =\"data/kc_house_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sum_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/with noise/The SUM dataset, with noise.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a2329a3d3c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msumdata_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumdata_noise_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Remove 'Instance' as it simply represents the row number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumdata_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msumdata_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Instance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msumdata_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/with noise/The SUM dataset, with noise.csv' does not exist"
     ]
    }
   ],
   "source": [
    "sumdata_noise = pd.read_csv(sumdata_noise_path, delimiter=\";\")\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "sumdata_noise = sumdata_noise.drop('Instance', axis = 1)\n",
    "sumdata_noise.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sum_noise dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiyim/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 'Nosiy Target' as regression target\n",
    "sumdata_noise_reg_Y = sumdata_noise['Noisy Target'].values.reshape(-1, 1)\n",
    "\n",
    "# Use 'Nosiy Target Class' Large Number as regression target\n",
    "sumdata_noise_classif_Y = pd.get_dummies(sumdata_noise['Noisy Target Class']).iloc[:, 0]\n",
    "sumdata_noise_classif_Y = sumdata_noise_classif_Y.values.astype(int).reshape(-1,1)\n",
    "\n",
    "# Use rest columns as explananatory variables\n",
    "# We can simply use the same features for both as Noisy Target and Noisy Target Class are representing the samething\n",
    "sumdata_noise_reg_X = sumdata_noise.iloc[:, 0:-2].values\n",
    "sumdata_noise_classif_X = sumdata_noise.iloc[:, 0:-2].values\n",
    "\n",
    "# Apply Feature Scaling for the classification variable\n",
    "# As we are using KNN \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "sumdata_noise_classif_X = scX.fit_transform(sumdata_noise_classif_X)\n",
    "sumdata_noise_classif_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sumdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5 (meaningless)</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57326</td>\n",
       "      <td>68791</td>\n",
       "      <td>82549</td>\n",
       "      <td>99059</td>\n",
       "      <td>72624</td>\n",
       "      <td>142645</td>\n",
       "      <td>171174</td>\n",
       "      <td>205409</td>\n",
       "      <td>246491</td>\n",
       "      <td>295789</td>\n",
       "      <td>1073444</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87859</td>\n",
       "      <td>105431</td>\n",
       "      <td>126517</td>\n",
       "      <td>151820</td>\n",
       "      <td>19982</td>\n",
       "      <td>218621</td>\n",
       "      <td>262345</td>\n",
       "      <td>314814</td>\n",
       "      <td>377777</td>\n",
       "      <td>453332</td>\n",
       "      <td>1645184</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23721</td>\n",
       "      <td>28465</td>\n",
       "      <td>34158</td>\n",
       "      <td>40990</td>\n",
       "      <td>20054</td>\n",
       "      <td>59026</td>\n",
       "      <td>70831</td>\n",
       "      <td>84997</td>\n",
       "      <td>101996</td>\n",
       "      <td>122395</td>\n",
       "      <td>444184</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24771</td>\n",
       "      <td>29725</td>\n",
       "      <td>35670</td>\n",
       "      <td>42804</td>\n",
       "      <td>7775</td>\n",
       "      <td>61638</td>\n",
       "      <td>73966</td>\n",
       "      <td>88759</td>\n",
       "      <td>106511</td>\n",
       "      <td>127813</td>\n",
       "      <td>463844</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47862</td>\n",
       "      <td>57434</td>\n",
       "      <td>68921</td>\n",
       "      <td>82705</td>\n",
       "      <td>60872</td>\n",
       "      <td>119095</td>\n",
       "      <td>142914</td>\n",
       "      <td>171497</td>\n",
       "      <td>205796</td>\n",
       "      <td>246955</td>\n",
       "      <td>896224</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35286</td>\n",
       "      <td>42343</td>\n",
       "      <td>50812</td>\n",
       "      <td>60974</td>\n",
       "      <td>51392</td>\n",
       "      <td>87803</td>\n",
       "      <td>105364</td>\n",
       "      <td>126437</td>\n",
       "      <td>151724</td>\n",
       "      <td>182069</td>\n",
       "      <td>660743</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14070</td>\n",
       "      <td>16884</td>\n",
       "      <td>20261</td>\n",
       "      <td>24313</td>\n",
       "      <td>1509</td>\n",
       "      <td>35011</td>\n",
       "      <td>42013</td>\n",
       "      <td>50416</td>\n",
       "      <td>60499</td>\n",
       "      <td>72599</td>\n",
       "      <td>263467</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34018</td>\n",
       "      <td>40822</td>\n",
       "      <td>48986</td>\n",
       "      <td>58783</td>\n",
       "      <td>38750</td>\n",
       "      <td>84648</td>\n",
       "      <td>101578</td>\n",
       "      <td>121894</td>\n",
       "      <td>146273</td>\n",
       "      <td>175528</td>\n",
       "      <td>637002</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36379</td>\n",
       "      <td>43655</td>\n",
       "      <td>52386</td>\n",
       "      <td>62863</td>\n",
       "      <td>29843</td>\n",
       "      <td>90523</td>\n",
       "      <td>108628</td>\n",
       "      <td>130354</td>\n",
       "      <td>156425</td>\n",
       "      <td>187710</td>\n",
       "      <td>681213</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25867</td>\n",
       "      <td>31040</td>\n",
       "      <td>37248</td>\n",
       "      <td>44698</td>\n",
       "      <td>92630</td>\n",
       "      <td>64366</td>\n",
       "      <td>77239</td>\n",
       "      <td>92687</td>\n",
       "      <td>111224</td>\n",
       "      <td>133469</td>\n",
       "      <td>484369</td>\n",
       "      <td>Large Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5 (meaningless)  \\\n",
       "0      57326      68791      82549      99059                    72624   \n",
       "1      87859     105431     126517     151820                    19982   \n",
       "2      23721      28465      34158      40990                    20054   \n",
       "3      24771      29725      35670      42804                     7775   \n",
       "4      47862      57434      68921      82705                    60872   \n",
       "5      35286      42343      50812      60974                    51392   \n",
       "6      14070      16884      20261      24313                     1509   \n",
       "7      34018      40822      48986      58783                    38750   \n",
       "8      36379      43655      52386      62863                    29843   \n",
       "9      25867      31040      37248      44698                    92630   \n",
       "\n",
       "   Feature 6  Feature 7  Feature 8  Feature 9  Feature 10   Target  \\\n",
       "0     142645     171174     205409     246491      295789  1073444   \n",
       "1     218621     262345     314814     377777      453332  1645184   \n",
       "2      59026      70831      84997     101996      122395   444184   \n",
       "3      61638      73966      88759     106511      127813   463844   \n",
       "4     119095     142914     171497     205796      246955   896224   \n",
       "5      87803     105364     126437     151724      182069   660743   \n",
       "6      35011      42013      50416      60499       72599   263467   \n",
       "7      84648     101578     121894     146273      175528   637002   \n",
       "8      90523     108628     130354     156425      187710   681213   \n",
       "9      64366      77239      92687     111224      133469   484369   \n",
       "\n",
       "        Target Class  \n",
       "0  Very Large Number  \n",
       "1  Very Large Number  \n",
       "2       Large Number  \n",
       "3       Large Number  \n",
       "4  Very Large Number  \n",
       "5  Very Large Number  \n",
       "6       Large Number  \n",
       "7  Very Large Number  \n",
       "8  Very Large Number  \n",
       "9       Large Number  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata = pd.read_csv(sumdata_path, delimiter=\";\")\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "sumdata = sumdata.drop('Instance', axis = 1)\n",
    "sumdata.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sumdata dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest of the columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiyim/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 'Nosiy Target' as regression target\n",
    "sumdata_reg_Y = sumdata['Target'].values.reshape(-1, 1)\n",
    "\n",
    "# Use 'Nosiy Target Class' Large Number as classification target\n",
    "sumdata_classif_Y = pd.get_dummies(sumdata['Target Class']).iloc[:, 0]\n",
    "sumdata_classif_Y = sumdata_classif_Y.values.astype(int).reshape(-1,1)\n",
    "\n",
    "# Use rest columns as explananatory variables\n",
    "# We can simply use the same features for both as Target and Target Class are representing the same thing\n",
    "sumdata_classif_X = sumdata.iloc[:, 0:-2].values\n",
    "sumdata_reg_X = sumdata.iloc[:, 0:-2].values\n",
    "\n",
    "# Apply Feature Scaling for the classification variable\n",
    "# As we are using KNN \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "sumdata_classif_X = scX.fit_transform(sumdata_classif_X)\n",
    "sumdata_classif_Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load census dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>industry code</th>\n",
       "      <th>occupation code</th>\n",
       "      <th>adjusted gross income</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enrolled in edu inst last wk</th>\n",
       "      <th>marital status</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>mace</th>\n",
       "      <th>hispanic Origin</th>\n",
       "      <th>sex</th>\n",
       "      <th>member of a labor union</th>\n",
       "      <th>reason for unemployment</th>\n",
       "      <th>full or part time employment stat</th>\n",
       "      <th>capital gains</th>\n",
       "      <th>capital losses</th>\n",
       "      <th>divdends from stocks</th>\n",
       "      <th>federal income tax liability</th>\n",
       "      <th>tax filer status</th>\n",
       "      <th>region of previous residence</th>\n",
       "      <th>state of previous residence</th>\n",
       "      <th>detailed household and family stat</th>\n",
       "      <th>detailed household summary in household</th>\n",
       "      <th>instance weight</th>\n",
       "      <th>migration code-change in msa</th>\n",
       "      <th>migration code-change in reg</th>\n",
       "      <th>migration code-move within reg</th>\n",
       "      <th>live in this house 1 year ago</th>\n",
       "      <th>migration prev res in sunbelt</th>\n",
       "      <th>num persons worked for employer</th>\n",
       "      <th>family members under 18</th>\n",
       "      <th>total person earnings</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>total person income</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>taxable income amount</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in labor force</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Other Rel 18+ ever marr not in subfamily</td>\n",
       "      <td>Other relative of householder</td>\n",
       "      <td>1700.09</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Head of household</td>\n",
       "      <td>South</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Householder</td>\n",
       "      <td>Householder</td>\n",
       "      <td>1053.55</td>\n",
       "      <td>MSA to MSA</td>\n",
       "      <td>Same county</td>\n",
       "      <td>Same county</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Asian or Pacific Islander</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in labor force</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Child 18+ never marr Not in a subfamily</td>\n",
       "      <td>Child 18 or older</td>\n",
       "      <td>991.95</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Child &lt;18 never marr not in subfamily</td>\n",
       "      <td>Child under 18 never married</td>\n",
       "      <td>1758.14</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>Both parents present</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Child &lt;18 never marr not in subfamily</td>\n",
       "      <td>Child under 18 never married</td>\n",
       "      <td>1069.16</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>Both parents present</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>Private</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>1200</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Professional specialty</td>\n",
       "      <td>Amer Indian Aleut or Eskimo</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joint both under 65</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Spouse of householder</td>\n",
       "      <td>Spouse of householder</td>\n",
       "      <td>162.61</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joint both under 65</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Householder</td>\n",
       "      <td>Householder</td>\n",
       "      <td>1535.86</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>6</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Handlers equip cleaners etc</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Job loser - on layoff</td>\n",
       "      <td>Unemployed full-time</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Secondary individual</td>\n",
       "      <td>Nonrelative of householder</td>\n",
       "      <td>898.83</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>Local government</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>876</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Education</td>\n",
       "      <td>Adm support including clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joint both under 65</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Spouse of householder</td>\n",
       "      <td>Spouse of householder</td>\n",
       "      <td>1661.53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>?</td>\n",
       "      <td>5</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Machine operators assmblrs &amp; inspctrs</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joint both under 65</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Householder</td>\n",
       "      <td>Householder</td>\n",
       "      <td>1146.79</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>6</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                  class of worker  industry code  occupation code  \\\n",
       "0   73                  Not in universe              0                0   \n",
       "1   58   Self-employed-not incorporated              4               34   \n",
       "2   18                  Not in universe              0                0   \n",
       "3    9                  Not in universe              0                0   \n",
       "4   10                  Not in universe              0                0   \n",
       "5   48                          Private             40               10   \n",
       "6   42                          Private             34                3   \n",
       "7   28                          Private              4               40   \n",
       "8   47                 Local government             43               26   \n",
       "9   34                          Private              4               37   \n",
       "\n",
       "         adjusted gross income  education     wage per hour  \\\n",
       "0         High school graduate          0   Not in universe   \n",
       "1   Some college but no degree          0   Not in universe   \n",
       "2                   10th grade          0       High school   \n",
       "3                     Children          0   Not in universe   \n",
       "4                     Children          0   Not in universe   \n",
       "5   Some college but no degree       1200   Not in universe   \n",
       "6   Bachelors degree(BA AB BS)          0   Not in universe   \n",
       "7         High school graduate          0   Not in universe   \n",
       "8   Some college but no degree        876   Not in universe   \n",
       "9   Some college but no degree          0   Not in universe   \n",
       "\n",
       "       enrolled in edu inst last wk                      marital status  \\\n",
       "0                           Widowed         Not in universe or children   \n",
       "1                          Divorced                        Construction   \n",
       "2                     Never married         Not in universe or children   \n",
       "3                     Never married         Not in universe or children   \n",
       "4                     Never married         Not in universe or children   \n",
       "5   Married-civilian spouse present                       Entertainment   \n",
       "6   Married-civilian spouse present   Finance insurance and real estate   \n",
       "7                     Never married                        Construction   \n",
       "8   Married-civilian spouse present                           Education   \n",
       "9   Married-civilian spouse present                        Construction   \n",
       "\n",
       "                      major industry code         major occupation code  \\\n",
       "0                         Not in universe                         White   \n",
       "1     Precision production craft & repair                         White   \n",
       "2                         Not in universe     Asian or Pacific Islander   \n",
       "3                         Not in universe                         White   \n",
       "4                         Not in universe                         White   \n",
       "5                  Professional specialty   Amer Indian Aleut or Eskimo   \n",
       "6          Executive admin and managerial                         White   \n",
       "7            Handlers equip cleaners etc                          White   \n",
       "8          Adm support including clerical                         White   \n",
       "9   Machine operators assmblrs & inspctrs                         White   \n",
       "\n",
       "         mace hispanic Origin               sex member of a labor union  \\\n",
       "0   All other          Female   Not in universe         Not in universe   \n",
       "1   All other            Male   Not in universe         Not in universe   \n",
       "2   All other          Female   Not in universe         Not in universe   \n",
       "3   All other          Female   Not in universe         Not in universe   \n",
       "4   All other          Female   Not in universe         Not in universe   \n",
       "5   All other          Female                No         Not in universe   \n",
       "6   All other            Male   Not in universe         Not in universe   \n",
       "7   All other          Female   Not in universe   Job loser - on layoff   \n",
       "8   All other          Female                No         Not in universe   \n",
       "9   All other            Male   Not in universe         Not in universe   \n",
       "\n",
       "     reason for unemployment  full or part time employment stat  \\\n",
       "0         Not in labor force                                  0   \n",
       "1   Children or Armed Forces                                  0   \n",
       "2         Not in labor force                                  0   \n",
       "3   Children or Armed Forces                                  0   \n",
       "4   Children or Armed Forces                                  0   \n",
       "5        Full-time schedules                                  0   \n",
       "6   Children or Armed Forces                               5178   \n",
       "7       Unemployed full-time                                  0   \n",
       "8        Full-time schedules                                  0   \n",
       "9   Children or Armed Forces                                  0   \n",
       "\n",
       "   capital gains  capital losses  divdends from stocks  \\\n",
       "0              0               0              Nonfiler   \n",
       "1              0               0     Head of household   \n",
       "2              0               0              Nonfiler   \n",
       "3              0               0              Nonfiler   \n",
       "4              0               0              Nonfiler   \n",
       "5              0               0   Joint both under 65   \n",
       "6              0               0   Joint both under 65   \n",
       "7              0               0                Single   \n",
       "8              0               0   Joint both under 65   \n",
       "9              0               0   Joint both under 65   \n",
       "\n",
       "  federal income tax liability  tax filer status  \\\n",
       "0              Not in universe   Not in universe   \n",
       "1                        South          Arkansas   \n",
       "2              Not in universe   Not in universe   \n",
       "3              Not in universe   Not in universe   \n",
       "4              Not in universe   Not in universe   \n",
       "5              Not in universe   Not in universe   \n",
       "6              Not in universe   Not in universe   \n",
       "7              Not in universe   Not in universe   \n",
       "8              Not in universe   Not in universe   \n",
       "9              Not in universe   Not in universe   \n",
       "\n",
       "                region of previous residence     state of previous residence  \\\n",
       "0   Other Rel 18+ ever marr not in subfamily   Other relative of householder   \n",
       "1                                Householder                     Householder   \n",
       "2    Child 18+ never marr Not in a subfamily               Child 18 or older   \n",
       "3      Child <18 never marr not in subfamily    Child under 18 never married   \n",
       "4      Child <18 never marr not in subfamily    Child under 18 never married   \n",
       "5                      Spouse of householder           Spouse of householder   \n",
       "6                                Householder                     Householder   \n",
       "7                       Secondary individual      Nonrelative of householder   \n",
       "8                      Spouse of householder           Spouse of householder   \n",
       "9                                Householder                     Householder   \n",
       "\n",
       "   detailed household and family stat detailed household summary in household  \\\n",
       "0                             1700.09                                       ?   \n",
       "1                             1053.55                              MSA to MSA   \n",
       "2                              991.95                                       ?   \n",
       "3                             1758.14                                Nonmover   \n",
       "4                             1069.16                                Nonmover   \n",
       "5                              162.61                                       ?   \n",
       "6                             1535.86                                Nonmover   \n",
       "7                              898.83                                       ?   \n",
       "8                             1661.53                                       ?   \n",
       "9                             1146.79                                Nonmover   \n",
       "\n",
       "  instance weight migration code-change in msa  \\\n",
       "0               ?                            ?   \n",
       "1     Same county                  Same county   \n",
       "2               ?                            ?   \n",
       "3        Nonmover                     Nonmover   \n",
       "4        Nonmover                     Nonmover   \n",
       "5               ?                            ?   \n",
       "6        Nonmover                     Nonmover   \n",
       "7               ?                            ?   \n",
       "8               ?                            ?   \n",
       "9        Nonmover                     Nonmover   \n",
       "\n",
       "        migration code-change in reg migration code-move within reg  \\\n",
       "0   Not in universe under 1 year old                              ?   \n",
       "1                                 No                            Yes   \n",
       "2   Not in universe under 1 year old                              ?   \n",
       "3                                Yes                Not in universe   \n",
       "4                                Yes                Not in universe   \n",
       "5   Not in universe under 1 year old                              ?   \n",
       "6                                Yes                Not in universe   \n",
       "7   Not in universe under 1 year old                              ?   \n",
       "8   Not in universe under 1 year old                              ?   \n",
       "9                                Yes                Not in universe   \n",
       "\n",
       "   live in this house 1 year ago migration prev res in sunbelt  \\\n",
       "0                              0               Not in universe   \n",
       "1                              1               Not in universe   \n",
       "2                              0               Not in universe   \n",
       "3                              0          Both parents present   \n",
       "4                              0          Both parents present   \n",
       "5                              1               Not in universe   \n",
       "6                              6               Not in universe   \n",
       "7                              4               Not in universe   \n",
       "8                              5               Not in universe   \n",
       "9                              6               Not in universe   \n",
       "\n",
       "  num persons worked for employer family members under 18  \\\n",
       "0                   United-States           United-States   \n",
       "1                   United-States           United-States   \n",
       "2                         Vietnam                 Vietnam   \n",
       "3                   United-States           United-States   \n",
       "4                   United-States           United-States   \n",
       "5                     Philippines           United-States   \n",
       "6                   United-States           United-States   \n",
       "7                   United-States           United-States   \n",
       "8                   United-States           United-States   \n",
       "9                   United-States           United-States   \n",
       "\n",
       "  total person earnings               country of birth father  \\\n",
       "0         United-States     Native- Born in the United States   \n",
       "1         United-States     Native- Born in the United States   \n",
       "2               Vietnam   Foreign born- Not a citizen of U S    \n",
       "3         United-States     Native- Born in the United States   \n",
       "4         United-States     Native- Born in the United States   \n",
       "5         United-States     Native- Born in the United States   \n",
       "6         United-States     Native- Born in the United States   \n",
       "7         United-States     Native- Born in the United States   \n",
       "8         United-States     Native- Born in the United States   \n",
       "9         United-States     Native- Born in the United States   \n",
       "\n",
       "   country of birth mother country of birth self  citizenship  \\\n",
       "0                        0       Not in universe            2   \n",
       "1                        0       Not in universe            2   \n",
       "2                        0       Not in universe            2   \n",
       "3                        0       Not in universe            0   \n",
       "4                        0       Not in universe            0   \n",
       "5                        2       Not in universe            2   \n",
       "6                        0       Not in universe            2   \n",
       "7                        0       Not in universe            2   \n",
       "8                        0       Not in universe            2   \n",
       "9                        0       Not in universe            2   \n",
       "\n",
       "   total person income  own business or self employed taxable income amount  \\\n",
       "0                    0                             95              - 50000.   \n",
       "1                   52                             94              - 50000.   \n",
       "2                    0                             95              - 50000.   \n",
       "3                    0                             94              - 50000.   \n",
       "4                    0                             94              - 50000.   \n",
       "5                   52                             95              - 50000.   \n",
       "6                   52                             94              - 50000.   \n",
       "7                   30                             95              - 50000.   \n",
       "8                   52                             95              - 50000.   \n",
       "9                   52                             94              - 50000.   \n",
       "\n",
       "   fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "0                                         NaN                NaN   \n",
       "1                                         NaN                NaN   \n",
       "2                                         NaN                NaN   \n",
       "3                                         NaN                NaN   \n",
       "4                                         NaN                NaN   \n",
       "5                                         NaN                NaN   \n",
       "6                                         NaN                NaN   \n",
       "7                                         NaN                NaN   \n",
       "8                                         NaN                NaN   \n",
       "9                                         NaN                NaN   \n",
       "\n",
       "   weeks worked in year  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "6                   NaN  \n",
       "7                   NaN  \n",
       "8                   NaN  \n",
       "9                   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = get_census_dataset()\n",
    " \n",
    "\n",
    "census.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess censu dataset\n",
    "\n",
    "- Remove 'Id' as it simply represents the row number\n",
    "- Use 'SalePrice' as regression target\n",
    "- Use 'SaleCondition' as classification target\n",
    "- For explananatory variables, use the following numerical variable and categorical variables\n",
    "    - Numerical\n",
    "        - LotFrontage\n",
    "        - OverallQual\n",
    "        - OverallCond\n",
    "        - YearBuilt\n",
    "        - YearRemodAdd\n",
    "        - TotalBsmtSF\n",
    "        - GrLivArea\n",
    "        - FullBath\n",
    "        - TotRmsAbvGrd\n",
    "        - GarageYrBlt\n",
    "        - GarageCars\n",
    "        - GarageArea\n",
    "        - LotArea\n",
    "        - 1stFlrSF\n",
    "        - 2ndFlrSF\n",
    "    - Categorical\n",
    "        - YearSold\n",
    "        - Neighborhood\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter unused categorical columns and drop NaN, we only want to keep 'neighborhood' and 'housestyle' \n",
    "## in our explanantory vairbale\n",
    "\n",
    "# get all the numerical data that is needed\n",
    "explanatory_numeric = ['OverallQual', 'LotFrontage', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', 'GrLivArea',\n",
    "                      'FullBath', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'LotArea', '1stFlrSF', '2ndFlrSF']\n",
    "\n",
    "housing_price[explanatory_numeric[0]]\n",
    "filtered_table = housing_price[explanatory_numeric[0]]\n",
    "filtered_table\n",
    "\n",
    "for c in explanatory_numeric[1:]:\n",
    "    filtered_table = pd.concat([filtered_table, housing_price[c]], axis=1)\n",
    "filtered_table\n",
    "\n",
    "# get the two categorical variable that we wants to use, convert it to dummy variable and avoid dummy variable trap\n",
    "filtered_table = pd.concat([filtered_table, pd.get_dummies(housing_price['Neighborhood']).iloc[:, :-1]], axis=1)\n",
    "filtered_table = pd.concat([filtered_table, pd.get_dummies(housing_price['YrSold']).iloc[:, :-1]], axis=1)\n",
    "\n",
    "# drop NaN\n",
    "filtered_table = filtered_table.dropna()\n",
    "filtered_table \n",
    "\n",
    "# get explanatory variable\n",
    "housing_price_reg_X = filtered_table[:].values\n",
    "housing_price_classif_X = filtered_table[:].values\n",
    "\n",
    "# get the regression target and classification target\n",
    "# I am using sales price as both regression and classification target\n",
    "# sale_price_classi = SalePrice<Mean, SalePrice>=Mean\n",
    "housing_price_reg_Y = housing_price['SalePrice'].values\n",
    "housing_price_classif_Y = np.zeros(housing_price_reg_Y.shape)\n",
    "house_price_mean = housing_price_reg_Y.mean()\n",
    "\n",
    "for i, price in enumerate(housing_price_reg_Y):\n",
    "    if price >= house_price_mean:\n",
    "        housing_price_classi_Y[i] = 1\n",
    "    else:\n",
    "        housing_price_classi_Y[i] = 0\n",
    "\n",
    "# Apply Feature Scaling to the numeric variables and regression target \n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "housing_price_classif_X = scX.fit_transform(housing_price_classif_X)\n",
    "housing_price_classif_Y = scY.fit_transform(housing_price_classif_Y.reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fits Algorithms to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_chunks = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000,\n",
    "1000000, 5000000, 10000000, 50000000, 100000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from math import sqrt\n",
    "def root_mean_square_error(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model( X, y, dataset_name, algorithm, isReg): \n",
    "    \n",
    "    print (\"Algorithm: {}\\nDataset: {}\\n\".format( algorithm.__name__, dataset_name))\n",
    "    for chunk in data_chunks:\n",
    "        \n",
    "        # if chunk is greater than the no. of examples quite from the chunking\n",
    "        if chunk > X.shape[0]: \n",
    "            chunk = X.shape[0]\n",
    "        \n",
    "        print (\"Chunk Size: {}\\n\".format(chunk))\n",
    "        \n",
    "        # generate the chunk file\n",
    "        current_X = X[0:chunk]\n",
    "        current_y = y[0:chunk]\n",
    "        \n",
    "        kFoldModelling(current_X, current_y, 10, algorithm, isReg)\n",
    "        \n",
    "        if chunk == X.shape[0]:\n",
    "            break\n",
    "              \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kFoldModelling (X, y, kfolds, algorithm, isReg):\n",
    "    \n",
    "    kf = KFold(n_splits=kfolds)\n",
    "    rmse = np.zeros((10,1))\n",
    "    mae = np.zeros((10,1))\n",
    "    accuracy = np.zeros((10,1))\n",
    "    precision = np.zeros((10,1))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # fit the model to the datset\n",
    "        lm = algorithm()\n",
    "        lm.fit(X_train, y_train)\n",
    "        \n",
    "        if isReg:     \n",
    "            rmse[i] = root_mean_square_error(y_test, lm.predict(X_test))  # RMSE https://www.kaggle.com/wiki/RootMeanSquaredError\n",
    "            mae[i] = mean_absolute_error(y_test, lm.predict(X_test))\n",
    "        else:\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            accuracy[i] = accuracy_score(y_test, lm.predict(X_test))\n",
    "            precision[i] = precision_score(y_test, lm.predict(X_test))\n",
    "        # print the result, we will need to have method that genereates the result csv file required.\n",
    "    \n",
    "    if isReg:     \n",
    "        print (\"Iteration: {}\\nRMSE: {}\\nMAE: {}\\n\".format( i, rmse.mean(), mae.mean()))\n",
    "    else:\n",
    "        print (\"Iteration: {}\\Accuracy: {}\\nPrecision: {}\\n\".format( i, accuracy.mean(), precision.mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fits Regression Algorithms to datasets\n",
    "\n",
    "    - Linear Regression\n",
    "    - Random Forest Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model(sumdata_noise_reg_X, sumdata_noise_reg_Y, \"The Sum Dataset(with noise)\", LinearRegression, True)\n",
    "# model(sumdata_reg_X, sumdata_reg_Y, \"The Sum Dataset(without noise)\",  LinearRegression, True)\n",
    "# model(housing_price_reg_X, housing_price_reg_Y, \"Housing Dataset\",  LinearRegression, True)\n",
    "# model(titanic_regression_X, titanic_regression_Y, \"Titanic Dataset\", LinearRegression, True)\n",
    "\n",
    "# model(sumdata_noise_reg_X, sumdata_noise_reg_Y,\"The Sum Dataset(with noise)\",  RandomForestRegressor, True)\n",
    "# model(sumdata_reg_X, sumdata_reg_Y, \"The Sum Dataset(without noise)\", RandomForestRegressor, True)\n",
    "# model(housing_price_reg_X, housing_price_reg_Y, \"Housing Dataset\", RandomForestRegressor, True)\n",
    "# model(titanic_regression_X, titanic_regression_Y, \"Titanic Dataset\", RandomForestRegressor, True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# model(sumdata_noise_classif_X, sumdata_noise_classif_Y, \"The Sum Dataset(with noise)\", LogisticRegression, False)\n",
    "# model(sumdata_classif_X, sumdata_classif_Y, \"The Sum Dataset(without noise)\", LogisticRegression, False)\n",
    "# model(housing_price_classif_X, housing_price_classif_Y, \"Housing Dataset\", LogisticRegression, False)\n",
    "housing_price_classif_Y\n",
    "# model(titanic_classification_X, titanic_classification_y, \"Titanic Dataset\", LogisticRegression, False)\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# model(sumdata_noise_classi_X, sumdata_noise_classif_Y, \"The Sum Dataset(with noise)\", SVC, False)\n",
    "# model(sumdata_classi_X, sumdata_classif_Y, \"The Sum Dataset(without noise)\", SVC, False)\n",
    "# model(housing_price_classi_X, housing_price_classif_Y, \"Housing Dataset\", SVC, False)\n",
    "# model(titanic_classification_X, titanic_classification_y, \"Titanic Dataset\", SVC, False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

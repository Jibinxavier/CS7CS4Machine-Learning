{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn.linear_model  as sk  # namespace conflict with pyspark\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff that needs to be done\n",
    "\n",
    "- Find another framework.\n",
    "    - Sklearn\n",
    "    - Spark\n",
    "    - Tensorflow/R\n",
    "- Algorithms\n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Maybe SVM /Random forest\n",
    "- Find two metrics \n",
    "    - RMSE \n",
    "    - Some other\n",
    "- Do 70/30 split training and 10 cross validation\n",
    "    - only did cross validation\n",
    "- Find another dataset \n",
    "    - Sum data with noise \n",
    "    -  Maybe housing data set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AABABUTdx7YqCeBquA1Ky7z8a/The%20SUM%20dataset?dl=1#\"\n",
    "housing_price_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AAAVLZzU4E7ro0BiRzPG3pP8a/House%20Prices?dl=1\"\n",
    "all_urls = [sumdata_url, housing_price_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_data(all_urls) # retrieves the data if there is no data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_noise_path = \"data/with noise/The SUM dataset, with noise.csv\"\n",
    "sumdata_path = \"data/without noise/The SUM dataset, without noise.csv\"\n",
    "housing_price_path = \"data/housing dataset.csv\" # has more than 30 features\n",
    "# need one more\n",
    "# what a brilliant idea to name files with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_chunks = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000,\n",
    "1000000, 5000000, 10000000, 50000000, 100000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sum_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5 (meaningless but please still use it)</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>Noisy Target</th>\n",
       "      <th>Noisy Target Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62485</td>\n",
       "      <td>58472</td>\n",
       "      <td>84200</td>\n",
       "      <td>86181</td>\n",
       "      <td>75529</td>\n",
       "      <td>136939</td>\n",
       "      <td>150633</td>\n",
       "      <td>230058</td>\n",
       "      <td>246491</td>\n",
       "      <td>257336</td>\n",
       "      <td>1352179</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Instance  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0         1      62485      58472      84200      86181   \n",
       "\n",
       "   Feature 5 (meaningless but please still use it)  Feature 6  Feature 7  \\\n",
       "0                                            75529     136939     150633   \n",
       "\n",
       "   Feature 8  Feature 9  Feature 10  Noisy Target Noisy Target Class  \n",
       "0     230058     246491      257336       1352179  Very Large Number  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata_noise = pd.read_csv(sumdata_noise_path, delimiter=\";\")\n",
    "sumdata_noise.head(n=1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sum_noise dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n",
    "\n",
    "# MADE A CHANGE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Remove 'Instance' as it simply represents the row number\n",
    "sumdata_noise.drop('Instance', axis = 1)\n",
    "\n",
    "# Extract 'Noisy Target' as regression target\n",
    "sumdata_noise_reg_Y = sumdata_noise[['Noisy Target']]\n",
    "\n",
    "# Extract 'Noisy Target Class' as regression target \n",
    "\n",
    "sumdata_noise_classif_Y ['Noisy Target Class'] = le.fit_transform( sumdata_noise ['Noisy Target Class'].astype('str')) \n",
    "\n",
    "# Extract rest columns as explananatory variables\n",
    "sumdata_noise_X = sumdata_noise.iloc[:, 1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras log reg\n",
    "def keras1DLogReg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    #Reshape and normalise inputs\n",
    "    X_train = X_train.as_matrix()\n",
    "    X_test = X_test.as_matrix()   \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    # encode class values as integers\"\n",
    "    encoder.fit(y_train) \n",
    "    encoded_y_train = encoder.transform(y_train)\n",
    "    encoder.fit(y_test)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    \n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    y_train = np_utils.to_categorical(encoded_y_train)\n",
    "    y_test = np_utils.to_categorical(encoded_y_test)\n",
    "    \n",
    "    \n",
    "    #Build the model\n",
    "    output_dim = y_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim = X_train.shape[1], activation='softmax'))\n",
    "    batch_size = 128\n",
    "    epochs = 20\n",
    "\n",
    "    #Compile ze model\n",
    "    model.compile(optimizer = 'sgd', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', 'precisin'])\n",
    "    history = model.fit(X_train, \n",
    "                        y_train, \n",
    "                        batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        verbose = 1,\n",
    "                        validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "    print ('Test score: ', score[0])\n",
    "    print ('Test accuracy', score[1])\n",
    "     \n",
    " \n",
    "    return (rmse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_cross_valdiation( X, y, dataset_name, algorithm, kfolds,regression=False): \n",
    "    \n",
    "    kf = KFold(n_splits=kfolds)\n",
    "    rmse = np.zeros((kfolds,1))\n",
    "    mae = np.zeros((kfolds,1))\n",
    "    accuracy = np.zeros((kfolds,1))\n",
    "    precision = np.zeros((kfolds,1))\n",
    "    \n",
    "    algorithm_n = algorithm.__name__ \n",
    " \n",
    "\n",
    "    for (i, (train_index, test_index)) in enumerate(kf.split(X)):\n",
    "\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "\n",
    "        # accumulating errors for each fold \n",
    "        # calculates mean across rows\n",
    "        if regression:     \n",
    "            rmse[i], mae[i] = algorithm( X_train, X_test, y_train, y_test)   # RMSE https://www.kaggle.com/wiki/RootMeanSquaredError\n",
    "           \n",
    "        else: \n",
    "            accuracy[i],precision[i] = algorithm( X_train, X_test, y_train, y_test)\n",
    "           \n",
    "    if regression:     \n",
    "        print (\"Dataset: {}\\nRMSE: {}\\nMAE: {}\\n\".format( dataset_name, rmse.mean(), mae.mean()))\n",
    "    else:\n",
    "        print (\"Dataset: {}\\Accuracy: {}\\nPrecision: {}\\n\".format(dataset_name, accuracy.mean(), precision.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 871321 samples, validate on 96814 samples\n",
      "Epoch 1/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 2/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 3/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 4/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 5/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 6/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 7/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 8/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 9/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 10/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 11/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 12/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 13/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 14/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 15/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 16/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 17/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 18/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 19/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Epoch 20/20\n",
      "871321/871321 [==============================] - 6s - loss: 13.0667 - acc: 0.1893 - val_loss: 13.0724 - val_acc: 0.1890\n",
      "Test score:  13.0724157505\n",
      "Test accuracy 0.188960274341\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.linear_model' has no attribute 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fa8e33ee9793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_cross_valdiation\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msumdata_noise_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumdata_noise_classif_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sum data with noise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras1DLogReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-20650f7eedc9>\u001b[0m in \u001b[0;36mmodel_cross_valdiation\u001b[0;34m(X, y, dataset_name, algorithm, kfolds, regression)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-a2b9efd556d2>\u001b[0m in \u001b[0;36mkeras1DLogReg\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.linear_model' has no attribute 'metrics'"
     ]
    }
   ],
   "source": [
    "model_cross_valdiation( sumdata_noise_X, sumdata_noise_classif_Y, \"Sum data with noise\", keras1DLogReg, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_test_split( X, y, dataset_name, algorithm, regression=False): \n",
    "    algorithm_n = algorithm.__name__\n",
    "    rmse = 0\n",
    "    mae = 0 \n",
    "    accuracy = 0\n",
    "    precision = 0  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "    if regression:     \n",
    "        rmse, mae = algorithm( X_train, X_test, y_train, y_test)   # RMSE https://www.kaggle.com/wiki/RootMeanSquaredError\n",
    "        print (\"Algorithm: {} Dataset: {}\\nRMSE: {}\\nMAE: {}\\n\".format( \n",
    "                                                                algorithm_n,\n",
    "                                                                dataset_name,\n",
    "                                                                rmse,\n",
    "                                                                mae))\n",
    "        \n",
    "    else: \n",
    "        accuracy ,precision  = algorithm( X_train, X_test, y_train, y_test)\n",
    "        # accumulating errors for each fold\n",
    "        print (\"Algorithm: {} Dataset: {}\\Accuracy: {}\\nPrecision: {}\\n\".format(\n",
    "                                                                algorithm_n,\n",
    "                                                                dataset_name,\n",
    "                                                                accuracy,\n",
    "                                                                precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test_split( sumdata_noise_X, sumdata_noise_classif_Y, \"Sum data with noise\", keras1DLogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s - loss: 1.2964 - acc: 0.6874 - val_loss: 0.8180 - val_acc: 0.8289\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.7190 - acc: 0.8393 - val_loss: 0.6106 - val_acc: 0.8625\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.5888 - acc: 0.8581 - val_loss: 0.5274 - val_acc: 0.8742\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.5264 - acc: 0.8686 - val_loss: 0.4811 - val_acc: 0.8805\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4885 - acc: 0.8751 - val_loss: 0.4510 - val_acc: 0.8854\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4624 - acc: 0.8791 - val_loss: 0.4293 - val_acc: 0.8890\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4431 - acc: 0.8831 - val_loss: 0.4130 - val_acc: 0.8926\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.4281 - acc: 0.8864 - val_loss: 0.4003 - val_acc: 0.8950\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4160 - acc: 0.8890 - val_loss: 0.3896 - val_acc: 0.8974\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4060 - acc: 0.8909 - val_loss: 0.3809 - val_acc: 0.8991\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3975 - acc: 0.8926 - val_loss: 0.3733 - val_acc: 0.9012\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3902 - acc: 0.8942 - val_loss: 0.3670 - val_acc: 0.9018\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3838 - acc: 0.8958 - val_loss: 0.3613 - val_acc: 0.9020\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3781 - acc: 0.8967 - val_loss: 0.3563 - val_acc: 0.9035\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3731 - acc: 0.8979 - val_loss: 0.3521 - val_acc: 0.9042\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3686 - acc: 0.8988 - val_loss: 0.3480 - val_acc: 0.9060\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3645 - acc: 0.8997 - val_loss: 0.3449 - val_acc: 0.9069\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3607 - acc: 0.9006 - val_loss: 0.3414 - val_acc: 0.9082\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3573 - acc: 0.9015 - val_loss: 0.3383 - val_acc: 0.9085\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3542 - acc: 0.9021 - val_loss: 0.3354 - val_acc: 0.9090\n",
      "Test score:  0.335369546378\n",
      "Test accuracy 0.909\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression using MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "keras1DLogReg(X_train, y_train, X_test, Y_test, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

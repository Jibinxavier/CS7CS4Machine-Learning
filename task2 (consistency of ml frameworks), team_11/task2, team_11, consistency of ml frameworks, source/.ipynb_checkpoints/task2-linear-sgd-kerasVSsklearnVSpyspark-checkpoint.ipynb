{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn  as sk  # namespace conflict with pyspark\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "import findspark\n",
    "import pyspark as pk\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import initializers, optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame works used\n",
    "\n",
    "- Keras\n",
    "- Spark\n",
    "- R\n",
    "- Sklearn\n",
    " \n",
    " \n",
    "### Find another dataset  \n",
    "- Maybe housing data set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AABABUTdx7YqCeBquA1Ky7z8a/The%20SUM%20dataset?dl=1#\"\n",
    "housing_url = \"https://www.dropbox.com/sh/euppz607r6gsen2/AAD6JGlvG5XADIjg9SCojvpya/House%20Sales%20in%20King%20County%2C%20USA?dl=1&preview=kc_house_data.csv\"\n",
    "all_urls = [sumdata_url,housing_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(all_urls) # retrieves the data if there is no data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdata_noise_path = \"data/with noise/The SUM dataset, with noise.csv\" \n",
    "housing_price_path =\"data/kc_house_data.csv\" # has more than 30 features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum Data restricted to 100,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUM_DATA_SIZE = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing restricted to 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOUSE_DATA_SIZE =10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets sum_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5 (meaningless but please still use it)</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>Noisy Target</th>\n",
       "      <th>Noisy Target Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62485</td>\n",
       "      <td>58472</td>\n",
       "      <td>84200</td>\n",
       "      <td>86181</td>\n",
       "      <td>75529</td>\n",
       "      <td>136939</td>\n",
       "      <td>150633</td>\n",
       "      <td>230058</td>\n",
       "      <td>246491</td>\n",
       "      <td>257336</td>\n",
       "      <td>1352179</td>\n",
       "      <td>Very Large Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Instance  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0         1      62485      58472      84200      86181   \n",
       "\n",
       "   Feature 5 (meaningless but please still use it)  Feature 6  Feature 7  \\\n",
       "0                                            75529     136939     150633   \n",
       "\n",
       "   Feature 8  Feature 9  Feature 10  Noisy Target Noisy Target Class  \n",
       "0     230058     246491      257336       1352179  Very Large Number  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata_noise = pd.read_csv(sumdata_noise_path, delimiter=\";\")\n",
    "sumdata_noise = sumdata_noise.head(n=SUM_DATA_SIZE)\n",
    "sumdata_noise.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess sum_noise dataset\n",
    "\n",
    "- Remove 'Instance' as it simply represents the row number\n",
    "- Extract 'Nosiy Target' as regression target\n",
    "- Extract 'Nosiy Class' as classification target\n",
    "- Extract rest columns as explananatory variables\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create same base line for Spark, Keras, Sklearn implementation\n",
    "- Using the same feature scaled data for all implementation\n",
    "- Same number iterations\n",
    "- Same cost function for minimising(for gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove 'Instance' as it simply represents the row number\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "sumdata_noise.drop('Instance', axis = 1)\n",
    "\n",
    "# Extract 'Nosiy Target' as regression target\n",
    "sumdata_noise_reg_Y = sumdata_noise.loc[:, ['Noisy Target']]\n",
    "# Extract 'Nosiy Target Class' as regression target\n",
    "sumdata_noise_classif_Y = sumdata_noise.loc[:, ['Noisy Target Class']] \n",
    " \n",
    " \n",
    " \n",
    "sumdata_noise_classif_Y ['Noisy Target Class'] = le.fit_transform( sumdata_noise_classif_Y ['Noisy Target Class'].astype('str')) \n",
    " \n",
    "# Extract rest columns as explananatory variables\n",
    "sumdata_noise_X =sumdata_noise.drop(['Instance','Noisy Target Class','Noisy Target'\n",
    "                                    ], axis = 1) \n",
    "# our SPARK NEEDS target column to be named \"label\"\n",
    "sumdata_noise_reg_Y.rename(columns={'Noisy Target': 'label'}, inplace=True)\n",
    "sumdata_noise_classif_Y.rename(columns={'Noisy Target Class': 'label'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "- Keeping them as dataframes (transform returns ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "columns = sumdata_noise_X.columns\n",
    "\n",
    "sumdata_noise_X[columns] =  scX.fit_transform(sumdata_noise_X)\n",
    "columns = sumdata_noise_reg_Y.columns\n",
    "sumdata_noise_reg_Y[columns] = scX.fit_transform(sumdata_noise_reg_Y)\n",
    "\n",
    "\n",
    "sumdata_noise_scaled = pd.concat([sumdata_noise_X,sumdata_noise_reg_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load House Price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3        1.0         1180   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_price = pd.read_csv(housing_price_path, delimiter=\",\")\n",
    "housing_price = housing_price.head(n=HOUSE_DATA_SIZE)\n",
    "housing_price.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess housing price dataset\n",
    "\n",
    "- Remove 'Id' as it simply represents the row number\n",
    "- Use 'price' as regression target\n",
    "- Use 'SaleCondition' as classification target\n",
    "- For explananatory variables, use the following numerical variable and categorical variables\n",
    "    - Numerical\n",
    "        - bedrooms\n",
    "        - bathrooms\n",
    "        - sqft_living\n",
    "        - sqft_lot\n",
    "        - condition\n",
    "        - sqft_above\n",
    "        - yr_built\n",
    "        - sqft_living15\n",
    "        - sqft_lot15\n",
    "- Apply Feature Scaling to the dataset \n",
    "\n",
    "- Ensure all dataframe has been converted to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'condition', 'sqft_above', 'yr_built', 'sqft_living15', 'sqft_lot15']] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e93b8e4421a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                       'sqft_living15', 'sqft_lot15']\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiltered_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Apply Feature Scaling to the classification variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot index with multidimensional key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_validate_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jibin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                 raise KeyError(\"None of [%s] are in the [%s]\" %\n\u001b[0;32m-> 1418\u001b[0;31m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'condition', 'sqft_above', 'yr_built', 'sqft_living15', 'sqft_lot15']] are in the [index]\""
     ]
    }
   ],
   "source": [
    "#Use 'price' as regression target \n",
    "housing_price_reg_Y = housing_price.loc[:, ['price']]\n",
    "\n",
    "# Use following features to predict price\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'condition', 'sqft_above', 'yr_built',\n",
    "                      'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "filtered_table = housing_price[features]\n",
    "\n",
    "# Apply Feature Scaling to the classification variable\n",
    "scX = StandardScaler()\n",
    "scY = StandardScaler()\n",
    "\n",
    "housing_price_reg_X = filtered_table\n",
    "columns = filtered_table.columns\n",
    "housing_price_reg_X[columns] = scX.fit_transform(housing_price_reg_X)\n",
    "columns = housing_price_reg_Y.columns\n",
    "housing_price_reg_Y[columns] = scX.fit_transform(housing_price_reg_Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spark_linear_regression( X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "        learning rate: cant configure it\n",
    "        epochs: 10 (maxiter)\n",
    "        batch size 1 \n",
    "        objective function is ordinary least squared error\n",
    "        root mean squared error for evaluating testdata\n",
    "    \"\"\"\n",
    "    from pyspark.ml import Pipeline  \n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_data = pd.concat([X_train,y_train], axis =1)\n",
    "    test_data  = pd.concat([X_test,y_test], axis =1)\n",
    "    \n",
    " \n",
    "    train_data = sqlContext.createDataFrame(train_data)\n",
    "    test_data = sqlContext.createDataFrame(test_data) \n",
    "   \n",
    "   \n",
    "    assembler = (VectorAssembler()\n",
    "        .setInputCols(train_data.columns[:-1]) # everything excluding target\n",
    "        .setOutputCol(\"features\"))\n",
    " \n",
    "    lr = pk.ml.regression.LinearRegression(maxIter=10)\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "    model = pipeline.fit(train_data)\n",
    "    \n",
    "    \n",
    "    predictions = model.transform(test_data) \n",
    "    \n",
    "    #predictions.select(\"predictions\", \"label\").toPandas()  \n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "    RMSE = evaluator.evaluate(predictions)\n",
    "    evaluator = RegressionEvaluator(metricName=\"mae\")\n",
    "    MAE = evaluator.evaluate(predictions)\n",
    "  \n",
    "    return RMSE,MAE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "def ols_error(y_true, y_pred):\n",
    "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def keras_linear_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "        learning rate 0.001\n",
    "        epochs 10\n",
    "        batch size 1 \n",
    "        objective function is ordinary least squared error\n",
    "        root mean squared error for evaluating testdata\n",
    "    \"\"\"\n",
    "    X_train = X_train.as_matrix()\n",
    "    X_test = X_test.as_matrix()\n",
    "    y_train = y_train.as_matrix()\n",
    "    y_test = y_test.as_matrix()\n",
    "    \n",
    "    cols = X_train.shape[1] # no of training examples\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(1, activation='linear', input_dim=cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "    sgd=optimizers.SGD(lr=0.001)\n",
    "    model.compile(optimizer=sgd ,loss=ols_error)\n",
    "    model.fit(X_train,y_train, epochs=10, shuffle=False, verbose=0)\n",
    "    preds = model.predict( X_test, verbose=0)\n",
    "    \n",
    "    mae =  sk.metrics.mean_absolute_error(y_test, preds)\n",
    "    rmse = sk.metrics.mean_squared_error(y_test, preds)**0.5\n",
    " \n",
    "    return (rmse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sklearn_linear_regression( X_train, X_test, y_train, y_test): \n",
    "    \"\"\"\n",
    "        learning rate 0.001\n",
    "        epochs 10\n",
    "        batch size 1\n",
    "        objective function is ordinary least squared error\n",
    "        root mean squared error for evaluating testdata\n",
    "       \n",
    "    \"\"\"\n",
    "    clf = sk.linear_model.SGDRegressor(learning_rate='constant', eta0=0.001,n_iter=10)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mae =  sk.metrics.mean_absolute_error(y_test, preds)\n",
    "    rmse = sk.metrics.mean_squared_error(y_test, preds)**0.5\n",
    "    return (rmse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_cross_validation( X, y, dataset_name, kfolds,algorithm): \n",
    "    kf = KFold(n_splits=kfolds)\n",
    "    rmse = np.zeros((kfolds,1))\n",
    "    mae = np.zeros((kfolds,1))\n",
    "     \n",
    "    \n",
    "    algorithm_n = algorithm.__name__ \n",
    " \n",
    "\n",
    "    for (i, (train_index, test_index)) in enumerate(kf.split(X)):\n",
    "\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "\n",
    "        # accumulating errors for each fold \n",
    "       \n",
    "       \n",
    "        rmse[i], mae[i] = algorithm( X_train, X_test, y_train, y_test)   # RMSE https://www.kaggle.com/wiki/RootMeanSquaredError\n",
    "    # calculates mean across rows\n",
    "    print (\"Dataset: {}\\nRMSE: {}\\nMAE: {}\\n\".format( dataset_name, rmse.mean(), mae.mean()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Sum data with noise\n",
      "RMSE: 0.12082316746374525\n",
      "MAE: 0.09157470959364587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cross_validation( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\",10 ,sklearn_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Sum data with noise\n",
      "RMSE: 0.11997793554549654\n",
      "MAE: 0.089825622765171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cross_validation( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\",10 , spark_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Sum data with noise\n",
      "RMSE: 0.12099053657889425\n",
      "MAE: 0.09056510972566621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cross_validation( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\",10, keras_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 70/30 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_test_split( X, y, dataset_name, algorithm): \n",
    "    algorithm_n = algorithm.__name__\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "    rmse,mae = algorithm( X_train, X_test, y_train, y_test)              \n",
    "    print (\"Algorithm: {}\\nDataset: {}\\nRMSE: {}\\nMAE: {}\\n\".format( algorithm_n,\n",
    "                                                                     dataset_name,\n",
    "                                                                     rmse,\n",
    "                                                                     mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: sklearn_linear_regression\n",
      "Dataset: Sum data with noise\n",
      "RMSE: 0.12022280408086701\n",
      "MAE: 0.09026104039063863\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_test_split( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\", sklearn_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: spark_linear_regression\n",
      "Dataset: Sum data with noise\n",
      "RMSE: 0.11993502599931348\n",
      "MAE: 0.089765625839784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_test_split( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\", spark_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: keras_linear_regression\n",
      "Dataset: Sum data with noise\n",
      "RMSE: 0.12412924843785682\n",
      "MAE: 0.09206387844999342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_test_split( sumdata_noise_X, sumdata_noise_reg_Y, \"Sum data with noise\", keras_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
